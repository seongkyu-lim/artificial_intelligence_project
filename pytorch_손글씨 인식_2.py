# -*- coding: utf-8 -*-
"""2015310908_임성규_hw5.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BGNxYv33hBJGLmGZBFf3GAWlnAGa4g10
"""

from google.colab import drive 
drive.mount('/content/gdrive/')

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision
import torch.nn.functional as F


from torch.utils.data import DataLoader, SubsetRandomSampler
from torch.nn import CrossEntropyLoss

import cv2
import numpy as np
import matplotlib.pyplot as plt

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, 64)
        self.fc5 = nn.Linear(64, 32)
        self.fc6 = nn.Linear(32, 10)
        self.drop = nn.Dropout(0.2)

    def forward(self, x):
        x = x.view(-1, 784)
        h1 = self.drop(F.relu(self.fc1(x)))
        h2 = self.drop(F.relu(self.fc2(h1)))
        h3 = self.drop(F.relu(self.fc3(h2)))
        h4 = self.drop(F.relu(self.fc4(h3)))
        h5 = self.drop(F.relu(self.fc5(h4)))
        h6 = self.fc6(h5)
        return h6
# torch.load(path)로 모델 전체 불러옴 -> 모델 클래스 선언 *

PATH2 = '/content/gdrive/My Drive/hw5/2015310908_임성규.pt'
net = torch.load(PATH2)
net.eval()

image = cv2.imread('/content/gdrive/My Drive/hw5/Image.jpg')
grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV)
contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
preprocessed_digits = []
for c in contours:
    x,y,w,h = cv2.boundingRect(c)
    
    # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)
    cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)
    
    # Cropping out the digit from the image corresponding to the current contours in the for loop
    digit = thresh[y:y+h, x:x+w]
    
    # Resizing that digit to (18, 18)
    resized_digit = cv2.resize(digit, (18,18))
    
    # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)
    padded_digit = np.pad(resized_digit, ((5,5),(5,5)), "constant", constant_values=0)
    
    # Adding the preprocessed digit to the list of preprocessed digits
    preprocessed_digits.append(padded_digit)
print("\n\n\n----------------Contoured Image--------------------")
plt.imshow(image, cmap="gray")
plt.show()
    
inp = np.array(preprocessed_digits)
print(inp.shape)

classes = ('0','1','2','3','4','5','6','7','8','9')

outputs = net(inp)

_, predicted = torch.max(outputs, 1)
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))

"""마지막 학습된 모델 로 인식하는것 실패"""



